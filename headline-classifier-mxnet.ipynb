{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end NLP: News Headline classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup execution role and session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4c1a412b-4535-46d5-8fe3-e8600801817a",
    "_uuid": "4e6801037e5274668f0b8667591d41c1abbe8be1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting. If you don't specify a bucket, SageMaker SDK will create a default bucket following a pre-defined naming convention in the same region. \n",
    "- The IAM role ARN used to give SageMaker access to your data. It can be fetched using the **get_execution_role** method from sagemaker python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::322418637044:role/service-role/AmazonSageMaker-ExecutionRole-20190409T203908\n",
      "CPU times: user 535 ms, sys: 66.3 ms, total: 601 ms\n",
      "Wall time: 773 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download News Aggregator Dataset available at the public UCI dataset repository (these files should already be downloaded in previous notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip NewsAggregatorDataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf __MACOSX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize the dataset\n",
    "\n",
    "We will load the newsCorpora.csv file to a Pandas dataframe for our data processing work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mxnet\n",
    "import re\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  \\\n",
       "1  Fed official says weak data caused by weather,...   \n",
       "2  Fed's Charles Plosser sees high bar for change...   \n",
       "3  US open: Stocks fall after Fed official hints ...   \n",
       "4  Fed risks falling 'behind the curve', Charles ...   \n",
       "5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "1  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "2  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "3  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "4  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "5  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "5        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
    "news_dataset = pd.read_csv('newsCorpora.csv', names=column_names, header=None, delimiter='\\t')\n",
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this exercice we'll only use the title (Headline) of the news story and the category as our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=news_dataset[['TITLE',\"CATEGORY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'b': 115967, 't': 108344, 'e': 152469, 'm': 45639})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(df['CATEGORY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has four categories: Business (b), Science & Technology (t), Entertainment (e) and Health & Medicine (m)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language pre processing\n",
    "\n",
    "We will do some basic processing of the text data to convert it into numerical form that the algorithm will be able to consume to create a model.\n",
    "We will do typical pre processing for NLP workloads such as: dummy encoding the labels, tokenizing the documents and set fixed sequence lengths for input feature dimension, padding documents to have fixed length input vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using MXNet backend\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "docs = df[\"TITLE\"].values\n",
    "\n",
    "encoder.fit(df[\"CATEGORY\"].values)\n",
    "encoded_Y = encoder.transform(df[\"CATEGORY\"].values)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-322418637044\n"
     ]
    }
   ],
   "source": [
    "#bucket = <bucket> # custom bucket name.\n",
    "s3_bucket = sess.default_bucket()\n",
    "s3_prefix = 'news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'e', 'm', 't']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize documents and set fixed sequence lengths for input feature dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "7bcf422f-0e75-4d49-b3b1-12553fcaf4ff",
    "_uuid": "46b7fc9aef5a519f96a295e980ba15deee781e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 75286\n",
      "Number of headlines: 422419\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(\"Vocabulary size: \" + str(vocab_size))\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 40\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(\"Number of headlines: \" + str(len(padded_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fed official says weak data caused by weather, should not slow taper'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 71291 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('./vectors.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "97ec3b51-53be-4078-a72a-a4222d2ffac0",
    "_uuid": "72b42e2a27337810e4604db0f67d626a62008854"
   },
   "outputs": [],
   "source": [
    "#print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "fa875535-7cef-40da-9add-dfe1d51395b0",
    "_uuid": "befd8941982ee2119daa0b9cc6b10a1e14656239"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir ./data/ ./data/embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save embedding matrix to push to S3 for Sagemaker to use during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "593bfd0a-b703-4e87-96dd-a7eb98e6940e",
    "_uuid": "f71c5f0b731d3418d3cb83be758233b5030da29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75286, 100)\n"
     ]
    }
   ],
   "source": [
    "#embedding_matrix.dump(\"ingredients-embedding-matrix.dat\")\n",
    "np.save(file=\"./data/embeddings/docs-embedding-matrix\",\n",
    "        arr=embedding_matrix,\n",
    "        allow_pickle=False)\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will prep the data for ingestion for the algortihm. Split the data set in train and test samples and uplad the data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, dummy_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/train/ data/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/train/train_X.npy', X_train)\n",
    "np.save('./data/train/train_Y.npy', y_train)\n",
    "np.save('./data/test/test_X.npy', X_test)\n",
    "np.save('./data/test/test_Y.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_s3_prefix = '{}/data/train'.format(s3_prefix)\n",
    "testdata_s3_prefix = '{}/data/test'.format(s3_prefix)\n",
    "embeddings_s3_prefix='{}/data/embeddings'.format(s3_prefix)\n",
    "output_s3 = 's3://{}/{}/models/'.format(s3_bucket, s3_prefix)\n",
    "code_location_s3 = 's3://{}/{}/codes'.format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3 = sess.upload_data(path='./data/train/', bucket=s3_bucket, key_prefix=traindata_s3_prefix)\n",
    "test_s3 = sess.upload_data(path='./data/test/', bucket=s3_bucket, key_prefix=testdata_s3_prefix)\n",
    "embeddings_s3 = sess.upload_data(path='./data/embeddings/', bucket=s3_bucket, key_prefix=embeddings_s3_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 's3://sagemaker-us-east-1-322418637044/news/data/train', 'test': 's3://sagemaker-us-east-1-322418637044/news/data/test', 'embeddings': 's3://sagemaker-us-east-1-322418637044/news/data/embeddings'}\n"
     ]
    }
   ],
   "source": [
    "inputs = {'train':train_s3, 'test': test_s3, 'embeddings': embeddings_s3}\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker training with differentiated infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the high level MXNet SDK to train our MXNet model using Sagemaker. We have packaged the code we used to build and train our model in the previous notebook (headline-classifier-local.ipynb). The training script is available in the tf-src directory. You can read the details of the script and format in the python file: keras_script_mxnet.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters to push to algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 5, 'vocab_size':vocab_size, 'num_classes':encoder.classes_.size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our `MXNet` estimator object, we have set the hyper-parameters for this object and we have our data channels linked with the algorithm. The only  remaining thing to do is to train the algorithm. The following command will train the algorithm. Training the algorithm involves a few steps. Firstly, the instance that we requested while creating the `MXNet` estimator classes is provisioned and is setup with the appropriate libraries. Then, the data from our channels are downloaded into the instance. Once this is done, the training job begins. The provisioning and data downloading will take some time, depending on the size of the data. \n",
    "\n",
    "Once the job has finished a \"Job complete\" message will be printed. The trained model can be found in the S3 bucket that was setup as `output_path` in the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the training job using a ml.p2.xlarge instance (GPUs) to accelerate our training. If your account runs into resource limits please use a ml.c5.xlarge instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-322418637044\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-2019-04-09-14-32-47-124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-09 14:32:47 Starting - Starting the training job...\n",
      "2019-04-09 14:32:51 Starting - Launching requested ML instances......\n",
      "2019-04-09 14:33:58 Starting - Preparing the instances for training.....\n",
      "\u001b[31m2019-04-09 14:34:57,956 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[31m2019-04-09 14:34:57,959 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-04-09 14:34:57,973 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_USER_ARGS': '[\"--epochs\",\"5\",\"--num_classes\",\"4\",\"--vocab_size\",\"75286\"]', 'SM_HP_EPOCHS': '5', 'SM_USER_ENTRY_POINT': 'keras_script_mxnet.py', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_HPS': '{\"epochs\":5,\"num_classes\":4,\"vocab_size\":75286}', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"embeddings\":\"/opt/ml/input/data/embeddings\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":5,\"num_classes\":4,\"vocab_size\":75286},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"embeddings\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-mxnet-2019-04-09-14-32-47-124\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-322418637044/sagemaker-mxnet-2019-04-09-14-32-47-124/source/sourcedir.tar.gz\",\"module_name\":\"keras_script_mxnet\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"keras_script_mxnet.py\"}', 'SM_HOSTS': '[\"algo-1\"]', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}', 'SM_NUM_CPUS': '4', 'SM_NETWORK_INTERFACE_NAME': 'ethwe', 'SM_HP_VOCAB_SIZE': '75286', 'SM_CURRENT_HOST': 'algo-1', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_NUM_CLASSES': '4', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-322418637044/sagemaker-mxnet-2019-04-09-14-32-47-124/source/sourcedir.tar.gz', 'SM_CHANNEL_TEST': '/opt/ml/input/data/test', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_CHANNEL_EMBEDDINGS': '/opt/ml/input/data/embeddings', 'SM_MODULE_NAME': 'keras_script_mxnet', 'SM_INPUT_DATA_CONFIG': '{\"embeddings\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNELS': '[\"embeddings\",\"test\",\"train\"]', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_LOG_LEVEL': '20', 'SM_NUM_GPUS': '0', 'SM_FRAMEWORK_PARAMS': '{}'}\u001b[0m\n",
      "\u001b[31m2019-04-09 14:34:58,373 sagemaker-containers INFO     Module keras_script_mxnet does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-04-09 14:34:58,373 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-04-09 14:34:58,373 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-04-09 14:34:58,374 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: keras-script-mxnet\n",
      "  Running setup.py bdist_wheel for keras-script-mxnet: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for keras-script-mxnet: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8peqzlti/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built keras-script-mxnet\u001b[0m\n",
      "\u001b[31mInstalling collected packages: keras-script-mxnet\u001b[0m\n",
      "\u001b[31mSuccessfully installed keras-script-mxnet-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.0.3 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-04-09 14:34:59,560 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-04-09 14:34:59,572 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 5,\n",
      "        \"num_classes\": 4,\n",
      "        \"vocab_size\": 75286\n",
      "    },\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"num_gpus\": 0,\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"embeddings\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"user_entry_point\": \"keras_script_mxnet.py\",\n",
      "    \"log_level\": 20,\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"embeddings\": \"/opt/ml/input/data/embeddings\"\n",
      "    },\n",
      "    \"job_name\": \"sagemaker-mxnet-2019-04-09-14-32-47-124\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"ethwe\"\n",
      "    },\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-322418637044/sagemaker-mxnet-2019-04-09-14-32-47-124/source/sourcedir.tar.gz\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"is_master\": true,\n",
      "    \"module_name\": \"keras_script_mxnet\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"5\",\"--num_classes\",\"4\",\"--vocab_size\",\"75286\"]\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=keras_script_mxnet.py\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":5,\"num_classes\":4,\"vocab_size\":75286}\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"embeddings\":\"/opt/ml/input/data/embeddings\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":5,\"num_classes\":4,\"vocab_size\":75286},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"embeddings\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-mxnet-2019-04-09-14-32-47-124\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-322418637044/sagemaker-mxnet-2019-04-09-14-32-47-124/source/sourcedir.tar.gz\",\"module_name\":\"keras_script_mxnet\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"keras_script_mxnet.py\"}\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_HP_VOCAB_SIZE=75286\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=keras_script_mxnet\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_HP_NUM_CLASSES=4\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-east-1-322418637044/sagemaker-mxnet-2019-04-09-14-32-47-124/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_EMBEDDINGS=/opt/ml/input/data/embeddings\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"embeddings\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"embeddings\",\"test\",\"train\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m keras_script_mxnet --epochs 5 --num_classes 4 --vocab_size 75286\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mUsing MXNet backend\u001b[0m\n",
      "\u001b[31mNamespace(embeddings='/opt/ml/input/data/embeddings', epochs=5, model_dir='/opt/ml/model', num_classes=4, output_data_dir='/opt/ml/output/data', test='/opt/ml/input/data/test', train='/opt/ml/input/data/train', vocab_size=75286)\u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[31m=================================================================\u001b[0m\n",
      "\u001b[31membed (Embedding)            (None, 40, 100)           7528600   \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_1 (Conv1D)              (None, 128, 98)           15488     \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mmaxpool_1 (MaxPooling1D)     (None, 25, 98)            0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mflat_1 (Flatten)             (None, 2450)              0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout_1 (Dropout)          (None, 2450)              0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdense_1 (Dense)              (None, 128)               313728    \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mout_1 (Dense)                (None, 4)                 516       \u001b[0m\n",
      "\u001b[31m=================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 7,858,332\u001b[0m\n",
      "\u001b[31mTrainable params: 329,732\u001b[0m\n",
      "\u001b[31mNon-trainable params: 7,528,600\u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mEpoch 1/5\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/mxnet/module/bucketing_module.py:408: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.0625). Is this intended?\n",
      "  force_init=force_init)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-04-09 14:34:58 Downloading - Downloading input data\n",
      "2019-04-09 14:34:58 Training - Training image download completed. Training in progress.\u001b[31m - 298s - loss: 0.3241 - acc: 0.8608\u001b[0m\n",
      "\u001b[31mEpoch 2/5\u001b[0m\n",
      "\u001b[31m - 301s - loss: 0.3052 - acc: 0.8696\u001b[0m\n",
      "\u001b[31mEpoch 3/5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mxnet_estimator = MXNet(entry_point='keras_script_mxnet.py',\n",
    "                       source_dir='./tf-src',\n",
    "                        role=role,\n",
    "                        train_instance_type='ml.p2.xlarge',\n",
    "                        train_instance_count=1,\n",
    "                        framework_version='1.3.0',\n",
    "                        py_version='py3',\n",
    "                        hyperparameters=hyperparameters)\n",
    "mxnet_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting / Inference\n",
    "Once the training is done, we can deploy the trained model as an Amazon SageMaker real-time hosted endpoint. This will allow us to make predictions (or inference) from the model. Note that we don't have to host on the same type of instance that we used to train. Because instance endpoints will be up and running for long, it's advisable to choose a cheaper instance for inference.\n",
    "\n",
    "We will deploy our model using the MXNetModel object that will recieve as input the model object output by the training job to S3. We can use the different features of Sagemaker as decoupled modules. You can bring a model trained outside of Sagemaker and deploy it using the Sagemaker model deployment api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "key = mxnet_estimator.model_data[mxnet_estimator.model_data.find(\"/\", 5)+1:]\n",
    "s3.Bucket(s3_bucket).download_file(key, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='model.tar.gz'\n",
    "from sagemaker.mxnet import MXNet, MXNetModel\n",
    "\n",
    "sagemaker_model = MXNetModel(model_data = model_path,\n",
    "                             role = role,\n",
    "                             entry_point = 'default_classifier.py',\n",
    "                             py_version='py3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-mxnet-2019-04-02-16-54-36-116\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-mxnet-2019-04-02-16-54-36-116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = mxnet_estimator.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your model should now be in production as a RESTful API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application/json'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'application/json'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor._JsonDeserializer at 0x7f1cca0c2eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'sagemaker-mxnet-2019-04-02-16-54-36-116'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.session.Session at 0x7f1c2d747908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor._JsonSerializer at 0x7f1cca0c2e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictor.accept, predictor.content_type, predictor.deserializer, predictor.endpoint, predictor.sagemaker_session, predictor.serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our model with an example headline. You can be creative with your headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_doc=['Senate prepares to vote on dueling plans to end shutdown']\n",
    "# integer encode the document\n",
    "encoded_example = t.texts_to_sequences(example_doc)\n",
    "\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 40\n",
    "padded_example = pad_sequences(encoded_example, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result represents the probability or confidence of the model that the headline represents one of the classes: 'b', 'e', 'm', 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9064793586730957,\n",
       "  0.005665271542966366,\n",
       "  0.006633899174630642,\n",
       "  0.08122153580188751]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(padded_example.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter_ranges = {'learning_rate': ContinuousParameter(0.01, 0.2)}\n",
    "hyperparameter_ranges = {'epochs': IntegerParameter(5, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'loss'\n",
    "objective_type = 'Minimize'\n",
    "metric_definitions = [{'Name': 'loss',\n",
    "                       'Regex': 'loss = ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 5, 'vocab_size':vocab_size, 'num_classes':encoder.classes_.size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxnet_estimator = MXNet(entry_point='keras_script_mxnet.py',\n",
    "                       source_dir='./tf-src',\n",
    "                        role=role,\n",
    "                        train_instance_type='ml.m4.xlarge',\n",
    "                        train_instance_count=1,\n",
    "                        framework_version='1.3.0',\n",
    "                        py_version='py3',\n",
    "                        hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(mxnet_estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=5,\n",
    "                            max_parallel_jobs=2,\n",
    "                            objective_type=objective_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sagemaker-mxnet-190402-1720\n"
     ]
    }
   ],
   "source": [
    "tuner.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
